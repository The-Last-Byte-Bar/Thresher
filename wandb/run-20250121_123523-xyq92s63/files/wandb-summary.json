{"train/explained_variance":-1.2779546,"eval/mean_reward":-3.5723388,"_step":3107,"train/loss":-1.9771405e-06,"train/value_loss":1.4994153e-05,"time/fps":637,"_runtime":861.640626855,"_wandb":{"runtime":861},"train/approx_kl":0,"global_step":547500,"train/policy_gradient_loss":1.26368835e-08,"train/learning_rate":3e-05,"_timestamp":1.737481783133018e+09,"train/clip_range":0.1,"train/clip_fraction":0,"eval/mean_ep_length":1,"train/entropy_loss":-0.0011625924}